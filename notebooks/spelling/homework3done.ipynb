{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bc9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "import textdistance\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be4490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbdeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = sum(vocab.values())\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word)\n",
    "    return similarities.most_common(topn)\n",
    "# возвр слова, которые ближе всего по расстоянию редактирования\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=1000)\n",
    "X = vec.fit_transform(vocab)\n",
    "\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn]\n",
    "    return [(id2word[top], similarities[top]) for top in topn]\n",
    "    # возвр слова, которые ближе всего по косинусному расстоянию\n",
    "\n",
    "# объединяем обе функции:\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4) # находим topn кандидатов по косинусному расстоянию\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    # из них выбираем наиболее близкое по расстоянию редактирования\n",
    "    # Было:\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67f8d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('воды', 0.6666666666666667), ('водыжу', 0.6666666666666667), ('своды', 0.5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Результат работы функции был такой:\n",
    "get_closest_hybrid_match('водыца', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bafe4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013442531432343428\n",
      "1.939759225446382e-07\n",
      "0.00013442531432343428\n"
     ]
    }
   ],
   "source": [
    "# у нас получилось 3 претендента, 2 из которых имеют одинаковое расстояние редактирования:\n",
    "# ('воды', 0.6666666666666667), ('водыжу', 0.6666666666666667)\n",
    "# Проверим буквально, какое из них более вероятное:\n",
    "print (P('воды'))\n",
    "print (P('водыжу'))\n",
    "print (max(P('воды'),P('водыжу')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# более вероятным оказалось слово \"воды\"\n",
    "# Переопределим последнюю функцию с учетом выбора по вероятности:\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4) # находим topn кандидатов по косинусному расстоянию\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    # из них выбираем наиболее близкое по расстоянию редактирования\n",
    "    return max(closest, key=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce88fdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('воды', 0.6666666666666667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('водыца', X, vec)\n",
    "# всё работает правильно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Там к словам применяется только одна операция - удаление символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово   \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4e7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a348e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letters(word_from_vocab):\n",
    "    \"Удаляем из слова по одной букве\"\n",
    "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits     = [(word_from_vocab[:i], word_from_vocab[i:])    for i in range(len(word_from_vocab) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    return set(deletes)\n",
    "\n",
    "cursed_vocab = {} # генерим словарь где ключ - слово с удаленной буквой, значение - список из всех адекватных слов\n",
    "# соответствующих этому удалению\n",
    "for w in vocab:\n",
    "    for i in delete_letters(w):\n",
    "        if i in cursed_vocab:\n",
    "            cursed_vocab[i].append(w)\n",
    "        else:\n",
    "            cursed_vocab[i] = [w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8a5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit(word_from_input):\n",
    "    \"Берем на вход слово из инпута, генерим к нему удаления, выбираем к каждому из словаря соответствий самое частотное слово\"\n",
    "    words = delete_letters(word_from_input)\n",
    "    # ищем совпадения в словаре удалений\n",
    "    candidates = []\n",
    "    for i in words:\n",
    "        if i in cursed_vocab:\n",
    "            candidates.append(max(cursed_vocab[i], key=P))\n",
    "    if len(candidates) == 0:\n",
    "        candidates.append(word_from_input)\n",
    "    return max(candidates, key=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79d9f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "медвежонок\n",
      "лошедб\n"
     ]
    }
   ],
   "source": [
    "print (best_fit('медвеженок'))\n",
    "print (best_fit('лошедб'))\n",
    "# работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137ca7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем, насколько хорош алгоритм\n",
    "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
    "# разобьем предложение по пробелам и удалим пунктуация на границах слов\n",
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2) # просто проверяем что длина одинаковая.\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2)) # zip = итератор, который объединяет элементы из нескольких ист-в данных (в кортеж?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f03311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "correct = 0 # правильных слов\n",
    "total = 0 # всего слов\n",
    "\n",
    "total_mistaken = 0 # \n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "cashed = {} # словарь слов, которые мы уже подавали на исправление\n",
    "# ключ - слово как оно было, значение = исправление\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i]) # в очередной раз соединили слова из двух словарей в пары\n",
    "    for pair in word_pairs:\n",
    "        # чтобы два раза не исправлять одно и тоже слово - закешируем его\n",
    "        # перед тем как считать исправление проверим нет ли его в кеше\n",
    "        predicted = cashed.get(pair[1], best_fit(pair[1]))\n",
    "        # dict.get(key[, default])\n",
    "        # Метод dict.get() возвращает значение для ключа key, если ключ находится в словаре\n",
    "        # если ключ отсутствует то вернет значение default.\n",
    "        cashed[pair[1]] = predicted # если исправленного слова нет в cashed, добавляем его\n",
    "        # это мы прям все слова из двух корпусов проверяем\n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1 # если слово, которое получилось, совпало с исходным, добавляем в правильные +1\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1 # считаем сколько изначально было правильных\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1 # считаем сколько иправилось с правильного на неправильный\n",
    "        else:\n",
    "            total_mistaken += 1 # всего было неправильных\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1 # исправилось правильно\n",
    "        \n",
    "    if not i % 100:\n",
    "        print(i) # просто следим чтоб работало?\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fea11ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4346173086543272\n",
      "0.21350931677018634\n",
      "0.5326748593086023\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)\n",
    "# вывод: алгоритм работает намного хуже, чем Норвиг из семинарской тетрадки.\n",
    "# мой алгоритм правильно сгенерировал только 43% слов, исправился правильно всего 21% из слов с опечаткой\n",
    "# из слов, которые были изначально правильные, алгоритм сломал больше половины"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292d96d",
   "metadata": {},
   "source": [
    "## *3. Настройка гиперпараметров. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b28f",
   "metadata": {},
   "source": [
    "У метода из первого задания много гиперпараметров (те которые нужно подбирать самостоятельно). Это параметры векторайзера, topn, метрика редактирования. Поэкспериментируйте с ними. \n",
    "\n",
    "Проведите как минимум 10 экспериментов с разными параметрами. Для каждого эксперимента укажите мотивацию (например, \"слишком маленький topn в get_closest_match_vec приводит к тому, что некоторые хорошие варианты не доходят до get_closest_match_with_metric, попробуем его увеличить\")\n",
    "\n",
    "Старайтесь получить улучшение, но если улучшить не получится, то это не страшно. Главное, чтобы эксперименты были осмысленными, а не рандомными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76843075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш кот тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
