{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fad453",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d056af4",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f532a8",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743d1d",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг <start>  \n",
    "    - еще одна матрица не нужна, можно по строкам хронить биграмы, а по колонкам униграммы  \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d078056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6afcef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach = open('2ch_corpus.txt').read()\n",
    "news = open('lenta.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8b19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9aaf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрезаем по 50 предложений из каждого корпуса для расчёта перплексии\n",
    "\n",
    "sentences_dvach = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "sentences_dvach_test = sentences_dvach[:50]\n",
    "sentences_dvach = sentences_dvach[50:]\n",
    "\n",
    "sentences_news = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]\n",
    "sentences_news_test = sentences_news[:50]\n",
    "sentences_news = sentences_news[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "trigrams_dvach = Counter()\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    bigrams_dvach.update(ngrammer(sentence))\n",
    "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
    "\n",
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "trigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence))\n",
    "    trigrams_news.update(ngrammer(sentence, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49e896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix\n",
    "matrix_dvach = lil_matrix((len(bigrams_dvach), len(unigrams_dvach)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8478496",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "id2bigram_dvach = list(bigrams_dvach)\n",
    "bigram2id_dvach = {bigram:i for i, bigram in enumerate(id2bigram_dvach)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c092d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngram in trigrams_dvach:\n",
    "    word0, word1, word3 = ngram.split()\n",
    "    word2 = word0+' '+word1\n",
    "    matrix_dvach[bigram2id_dvach[word2],word2id_dvach[word3]] =  (trigrams_dvach[ngram]/bigrams_dvach[word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516e7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = csr_matrix(matrix_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27aaeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_news = lil_matrix((len(bigrams_news), \n",
    "                   len(unigrams_news)))\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)} # словарь\n",
    "id2bigram_news = list(bigrams_news)\n",
    "bigram2id_news = {bigram:i for i, bigram in enumerate(id2bigram_news)}\n",
    "for ngram in trigrams_news:\n",
    "    word0, word1, word3 = ngram.split()\n",
    "    word2 = word0+' '+word1\n",
    "    matrix_news[bigram2id_news[word2],word2id_news[word3]] =  (trigrams_news[ngram]/bigrams_news[word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f4b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_news = csr_matrix(matrix_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ddb8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2bigram, id2word, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "#         chosen = np.random.choice(list(range(matrix.shape[1]))) # НЕПОН\n",
    "        chosen = np.random.choice(list(range(matrix.shape[1])), p=matrix[current_idx].toarray()[0]) # НЕПОН\n",
    "        text.append(id2word[chosen])\n",
    "\n",
    "        if id2word[chosen] == '<end>':\n",
    "            current_idx = bigram2id[start]\n",
    "        else:        \n",
    "            current_idx = bigram2id [id2bigram[current_idx].split( )[1] + ' ' + id2word[chosen]]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb489ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "можешь попробовать потасковать . хочу двачетянку с политача чтобы она пережила хотя бы потому что у меня было овердохуя нет . прогрессирующий паралич . их много а я забыл . анон . просрала значит просрала . попробуй да и весила примерно 110 кг . значит это украина . почему моча в чайнике — моча . рабочий сам может распорядиться 75 долларами купить сырьё оплатить ренту этц . и к тому что тебе наступили на чсв и того что она будет тебя с руками сам тоже не менее за годы простоя покрылся грязью да краска облупилась и смазать надо какой-то ванильный\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2bigram_dvach, id2word_dvach, bigram2id_dvach).replace('<end> ', '. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb7a598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "федеральная служба охраны и обороны а также в километре восточнее села шатили которое находится за пределами своего государства \n",
      " остановившись на отметке 25,93 доллара за акцию нк лукойл опустились на 2,98 процента и остановился на первый взгляд более сложная техника считает он \n",
      " в случае наводнения \n",
      " приносим извинения всем пользователям в июле движение фалуньгун было признано отсутствие средств на восстановительные и эвакуационные работы потребуется как минимум две недели когда у совета федерации и дума его повторно обратиться к президенту россии члены первого американского сетевого туристического клуба \n",
      " инуи один из лидеров корсиканских националистов шарлю сантони \n",
      " мы можем получить\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2bigram_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50295794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "по его словам прежде чем выложить на сайт playboy com \n",
      " специалисты полагают что потери боевиков составили не менее 30 автомобилей \n",
      " по словам авдеева несмотря на массовый характер и выбираем формат приглашенных исходя из размера среднемесячной зарплаты во втором тайме все изменилось после того как многие инфицированные лечатся самостоятельно в домашних условиях \n",
      " сейчас работа между ними зафиксировано более 230 аварий \n",
      " упрощается также система связи которой в результате столкновения грузовой самолет и погибли еще 12 лет \n",
      " в среду microsoft и www noch-einmal de \n",
      " центризбирком будет отстаивать свои честь и достоинство судьи \n",
      " автомобильное движение по садовому\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2bigram_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90c3463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "согласно решению федерального суда швейцарии \n",
      " последние с этим договором авторы должны согласиться с тем аналитики на биржах резко подскочили продажи последних версий антивирусного программного обеспечения аппаратуры и всего сразу \n",
      " главным итогом голосования является то что на одной из наиболее значительных исторических событий из тех таймеров которые были приобретены из государственного русского музея лидеры двух стран в управление фсб по чеченской республике николая кошмана в понедельник взрыв большой мощности \n",
      " следует проводить взвешенную кадровую политику и открыть границы для иностранцев сумма эта может и не серебряные призеры первенства а ставшие третьими французы сара абитболь и стефан бернарди \n",
      " начиная\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2bigram_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f754ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "согласно тому же не торопятся япония приняла решение сформировать согласительную комиссию для изучения экономических отношений \n",
      " монтани был арестован генеральный директор оао внуковские авиалинии александр красненкер и другие службы государственной безопасности грузии был осужден рижским судом на шесть лет назад владелец рукописи запрашивал за нее кого-нибудь наказать фрацузский программист с высшим образованием серж хампич взломал систему платежных карточек \n",
      " аушев заявил журналистам риа новости \n",
      " иосиро мори \n",
      " подозрительный предмет напоминающий взрывное устройство привел в действие находившийся в автомашине офицер получил смертельное ранение \n",
      " поезд вышедший в 11 15 по 22 июня 1999 года они были обнаружены в населенных пунктах\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2bigram_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2cb12",
   "metadata": {},
   "source": [
    "Считаем перплексию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5adcecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probas):\n",
    "    p = np.exp(np.sum(probas))\n",
    "    N = len(probas)\n",
    "    \n",
    "    return p**(-1/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418ee0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_perpl(test_set):\n",
    "    perpl_mean = {'dvach':[], 'news':[]}\n",
    "    perpl_sum_dvach = []\n",
    "    perpl_sum_news = []\n",
    "    for sent in test_set:\n",
    "        prob = {'dvach':[], 'news':[]}\n",
    "        for ngram in ngrammer(sent,n=3):\n",
    "            word0, word1, word3 = ngram.split()\n",
    "            word2 = word0+' '+word1\n",
    "            if word2 in bigrams_dvach and ngram in trigrams_dvach:\n",
    "                prob['dvach'].append(np.log(trigrams_dvach[ngram]/bigrams_dvach[word2]))\n",
    "            else:\n",
    "                prob['dvach'].append(np.log(0.00001))\n",
    "            if word2 in bigrams_news and ngram in trigrams_news:\n",
    "                prob['news'].append(np.log(trigrams_news[ngram]/bigrams_news[word2]))\n",
    "            else:\n",
    "                prob['news'].append(np.log(0.00001))\n",
    "        if perplexity(prob['dvach'])!= np.inf: \n",
    "            perpl_sum_dvach.append(perplexity(prob['dvach']))\n",
    "        if perplexity(prob['news'])!= np.inf: \n",
    "            perpl_sum_news.append(perplexity(prob['news']))\n",
    "    perpl_mean['dvach'] = sum(perpl_sum_dvach)/len(perpl_sum_dvach)\n",
    "    perpl_mean['news'] = sum(perpl_sum_news)/len(perpl_sum_news)\n",
    "    return perpl_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "672f8d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dvach': 30041.809295252246, 'news': 73947.63331484623}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_perpl(sentences_dvach_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38e487bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dvach': 60590.053280562846, 'news': 57784.239645627255}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_perpl(sentences_news_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a8dd5",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36c44b",
   "metadata": {},
   "source": [
    "Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b1bd8",
   "metadata": {},
   "source": [
    "Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf844",
   "metadata": {},
   "source": [
    "1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1c152",
   "metadata": {},
   "source": [
    "2. Что такое сглаживание (smoothing)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
